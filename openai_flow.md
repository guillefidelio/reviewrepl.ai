# OpenAI API Flow Documentation

This document outlines the complete flow of how our application communicates with OpenAI's new Responses API, from sending requests to receiving and processing responses.

## Overview

Our application uses OpenAI's new **Responses API** (`/v1/responses`) instead of the legacy Chat Completions API. This provides better performance, more predictable response structures, and is designed for GPT-5 models.

## API Endpoint

```
POST https://api.openai.com/v1/responses
```

## 1. Data Flow: Application ‚Üí OpenAI

### Request Structure

The application sends data to OpenAI through the `callOpenAI` method in `src/workers/job-processor.ts`:

```typescript
// Call OpenAI API using the new Responses API
private async callOpenAI(requestBody: Record<string, unknown>): Promise<OpenAIResponse> {
  try {
    const response = await fetch('https://api.openai.com/v1/responses', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
        'OpenAI-Project': OPENAI_PROJECT_ID,
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    return await response.json();

  } catch (error) {
    console.error('‚ùå OpenAI API call failed:', error);
    throw error;
  }
}
```

### Request Body Examples

#### AI Generation Job
```typescript
const requestBody = {
  model: 'gpt-4o-mini',
  input: `Generate a response to this customer review: "The service was excellent!"`,
  instructions: `You are a professional business response generator. Create a professional response to customer reviews. Keep responses under 150 characters. Be helpful, professional, and address the customer's feedback appropriately.`,
  max_output_tokens: 37, // Math.floor(150 / 4)
  temperature: 1
};
```

#### Review Processing Job
```typescript
const requestBody = {
  model: 'gpt-4o-mini',
  input: `Analyze this review: "The food was amazing but the wait time was too long."`,
  instructions: `Analyze this customer review and provide insights. Business category: restaurant`,
  max_output_tokens: 200,
  temperature: 1
};
```

#### Prompt Analysis Job
```typescript
const requestBody = {
  model: 'gpt-4o-mini',
  input: `Optimize this prompt: "Write a response to a customer review."`,
  instructions: `Optimize this prompt for clarity. Provide specific improvements and an optimized version.`,
  max_output_tokens: 300,
  temperature: 1
};
```

#### Sentiment Analysis Job
```typescript
const requestBody = {
  model: 'gpt-4o-mini',
  input: `Analyze sentiment: "I love this product! It's exactly what I needed."`,
  instructions: `Perform basic sentiment analysis on this text. Provide sentiment score, key emotions, and insights.`,
  max_output_tokens: 250,
  temperature: 1
};
```

## 2. OpenAI Response Structure

### Expected Response Format

OpenAI returns responses in this structure:

```typescript
interface OpenAIResponse {
  output: Array<{
    type: string;           // Usually "message"
    id: string;            // Unique message ID
    status: string;        // Usually "completed"
    role: string;          // Usually "assistant"
    content: Array<{
      type: string;        // Usually "output_text"
      text: string;        // The generated content
      annotations?: Array<unknown>; // Optional annotations
    }>;
  }>;
  usage?: {
    total_tokens: number;  // Total tokens used
  };
}
```

### Example Response

```json
{
  "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
  "object": "response",
  "created_at": 1741476542,
  "status": "completed",
  "error": null,
  "model": "gpt-4o-mini",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "Thank you for your wonderful feedback! We're thrilled that you had an excellent experience with our service. Your satisfaction is our top priority, and we look forward to serving you again soon.",
          "annotations": []
        }
      ]
    }
  ],
  "usage": {
    "input_tokens": 45,
    "output_tokens": 38,
    "total_tokens": 83
  }
}
```

## 3. Response Processing: OpenAI ‚Üí Application

### Content Extraction

The application extracts the generated content using this pattern:

```typescript
// Extract response from the new API structure
const generatedContent = response.output?.[0]?.content?.[0]?.text;

// Safety check
if (!generatedContent) {
  throw new Error('No content generated by OpenAI API');
}
```

### Complete Processing Example

Here's how the AI Generation job processes the response:

```typescript
// Process AI generation job
private async processAIGeneration(payload: Record<string, unknown>): Promise<Record<string, unknown>> {
  const { review_text, tone = 'professional', max_length = 150, business_profile, custom_prompt } = payload;

  if (!review_text || typeof review_text !== 'string') {
    throw new Error('review_text is required and must be a string');
  }

  // Ensure max_length is a number
  const maxLength = typeof max_length === 'number' ? max_length : 150;

  console.log(`ü§ñ Generating AI response for review: "${review_text.substring(0, 50)}..."`);

  // Generate the appropriate system prompt
  let systemPrompt: string;
  
  if (custom_prompt && typeof custom_prompt === 'string' && custom_prompt.trim().length > 0) {
    // For Pro mode with custom prompt
    systemPrompt = getSystemPromptForJob(
      {}, // Empty business profile for Pro mode
      'ai_generation',
      custom_prompt
    );
  } else if (business_profile && typeof business_profile === 'object') {
    // For Simple mode with business profile
    systemPrompt = getSystemPromptForJob(
      business_profile as Record<string, unknown>,
      'ai_generation'
    );
  } else {
    // Fallback to basic prompt
    systemPrompt = `You are a professional business response generator. Create a ${tone} response to customer reviews. Keep responses under ${maxLength} characters. Be helpful, professional, and address the customer's feedback appropriately.`;
  }

  console.log(`üìù Using system prompt: ${systemPrompt.substring(0, 100)}...`);

  // Call OpenAI API with the new Responses API
  const response = await this.callOpenAI({
    model: 'gpt-4o-mini',
    input: `Generate a response to this customer review: "${review_text}"`,
    instructions: systemPrompt,
    max_output_tokens: Math.floor(maxLength / 4),
    temperature: 1
  });

  // Extract response from the new API structure
  const generatedContent = response.output?.[0]?.content?.[0]?.text;
  if (!generatedContent) {
    throw new Error('No content generated by OpenAI API');
  }

  return {
    generated_response: generatedContent,
    confidence_score: 0.95,
    processing_time_ms: Date.now(),
    tokens_used: response.usage?.total_tokens || 0,
    model_used: 'gpt-4o-mini',
    tone_used: tone,
    max_length_requested: maxLength,
    system_prompt_used: systemPrompt
  };
}
```

## 4. Key Differences from Legacy API

| Legacy Chat Completions API | New Responses API |
|------------------------------|-------------------|
| `/v1/chat/completions` | `/v1/responses` |
| `messages` array with `role` and `content` | `input` + `instructions` |
| `max_tokens` | `max_output_tokens` |
| `response.choices[0].message.content` | `response.output[0].content[0].text` |
| Complex message threading | Simplified input/output structure |

## 5. Error Handling

### API Errors
```typescript
if (!response.ok) {
  const errorData = await response.json();
  throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
}
```

### Content Validation
```typescript
const generatedContent = response.output?.[0]?.content?.[0]?.text;
if (!generatedContent) {
  throw new Error('No content generated by OpenAI API');
}
```

### Network Errors
```typescript
} catch (error) {
  console.error('‚ùå OpenAI API call failed:', error);
  throw error;
}
```

## 6. Token Management

### Input Tokens
- System instructions (instructions parameter)
- User input (input parameter)
- Any additional context

### Output Tokens
- Generated response text
- Limited by `max_output_tokens` parameter

### Token Calculation
```typescript
// Rough estimate: divide desired character limit by 4
max_output_tokens: Math.floor(maxLength / 4)
```

## 7. Temperature and Creativity

- **Temperature: 1** (default) - Balanced creativity and focus
- **Range: 0-2** - Lower values are more focused, higher values more creative
- **Current Setting: 1** - Optimal for business responses

## 8. Model Configuration

- **Model: gpt-4o-mini** - Latest GPT-5 model optimized for efficiency
- **Capabilities**: Text generation, analysis, optimization
- **Best For**: Business applications, customer service, content generation

## 9. Response Validation

### Required Fields
- `response.output` array must exist
- `response.output[0]` must exist
- `response.output[0].content` array must exist
- `response.output[0].content[0].text` must contain generated content

### Optional Fields
- `response.usage.total_tokens` for token tracking
- `response.id` for response identification
- `response.status` for completion status

## 10. Testing the Flow

### Test Request
```bash
curl https://api.openai.com/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o-mini",
    "input": "Generate a response to this customer review: \"Great service!\"",
    "instructions": "You are a professional business response generator. Create a professional response to customer reviews. Keep responses under 150 characters.",
    "max_output_tokens": 37,
    "temperature": 1
  }'
```

### Expected Response
```json
{
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "Thank you for your positive feedback! We're delighted you had a great experience with our service."
        }
      ]
    }
  ],
  "usage": {
    "total_tokens": 45
  }
}
```

## Summary

The flow ensures:
1. **Structured Input**: Clear separation between user input and system instructions
2. **Predictable Output**: Consistent response structure for easy parsing
3. **Error Handling**: Comprehensive error checking at each step
4. **Token Management**: Efficient use of API tokens
5. **Content Validation**: Ensures generated content is available before processing

This architecture provides a robust foundation for AI-powered business applications while maintaining clear separation of concerns and comprehensive error handling.
